{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6adf6a5",
   "metadata": {},
   "source": [
    " # Hypothesis\n",
    " - weight와 bias를 0으로 초기화\n",
    " - requires_grad = True : 학습할 것이라고 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cfbf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ff55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "hypothesis = x_train*W+b # y = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3db5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function 설명\n",
    "# torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided,\\\n",
    "#             device=None, requires_grad=False)\n",
    "\n",
    "# -> 스칼라 값이 0으로 채워진 텐서를 반환하는 함수 (size로 정의된 크기의 텐서)\n",
    "# size : 수, 리스트, 튜플이 들어와도 됨\n",
    "# out : output 텐서\n",
    "# dtype : 데이터 타입\n",
    "# layout : 반환되는 텐서의 레이아웃 설정\n",
    "# device : 텐서의 device\n",
    "# requires_grad : 학습할 것이라고 명시해 주는 역할\n",
    "\n",
    "# pytorch의 autograd 패키지 : tensor의 모든 연산에 대해 자동 미분 제공\n",
    "# torch.Tensor 클래스에서 .requires_grad 속성을 True로 하면 모든 연산을 추적함\n",
    "# -> backword()를 호출하여 모든 변화도를 자동으로 계산 가능\n",
    "# 즉 연산을 기록하는 역할 -> 학습할 것을 명시!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952582fb",
   "metadata": {},
   "source": [
    "# MSE : 평균 제곱 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6baf8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train)**2)\n",
    "# optim.SGD를 통해서 학습 가능!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a697d48",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b3846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W,b], lr=0.01) # 러닝 레이트 : 0.01\n",
    "\n",
    "optimizer.zero_grad() # zero_grad()로 gradient 초기화\n",
    "cost.backward() # backward()로 gradient 계산\n",
    "optimizer.step() # step()으로 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4574fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### optimizer 설명\n",
    "# 학습시킬 변수들의 리스트를 집어넣음 : W, b\n",
    "# 러닝레이트도 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb204b08",
   "metadata": {},
   "source": [
    "# Full training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e114a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([W,b], lr=0.01) \n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(1, nb_epochs + 1): # 1~1000\n",
    "    hypothesis = x_train*W+b\n",
    "    cost = torch.mean((hypothesis - y_train)**2)  \n",
    "    \n",
    "    optimizer.zero_grad() \n",
    "    cost.backward() \n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32041a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9708], requires_grad=True) tensor([0.0664], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
