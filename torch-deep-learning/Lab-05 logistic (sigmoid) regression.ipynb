{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36b6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목차\n",
    "# 1.\n",
    "# logistic regression\n",
    "# binary에 대한 cost를 자동으로 만들어주는 함수\n",
    "# 전체 트레이닝 과정\n",
    "# 2. \n",
    "# 평가\n",
    "# 3.\n",
    "# 클래스를 이용해서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6e5e4",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "- m by d -> m by 1 (0과1)\n",
    "- sigmoid function -> 1/(1+e^(-X * W))\n",
    "- 여기서 |X * W| = (m,d) * (d,1) = (m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 것들\n",
    "# 1. 도구 불러오기\n",
    "# 2. 피쳐 데이터와 레이블 데이터 가져오기, tensor화 시키기\n",
    "# 3. 예측 모델 W, b 만들기\n",
    "# 4. 가설함수\n",
    "# 5. loss 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1286b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # 뉴럴 네트워크를 생성하기 위한 도구\n",
    "import torch.nn.functional as F # loss function 쉽게 불러오기 위해서\n",
    "import torch.optim as optim # optimizer 쉽게 만들기 위하여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f000a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb5084fbe50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c4c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]] # (6,2) 데이터\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab022f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 토치텐서 형식으로 변환해줌\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f6e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 함수 만들기\n",
    "W = torch.zeros((2,1), requires_grad=True)\n",
    "# W가 2,1인 이유는 들어오는 데이터가 6*2이기 때문에 6*1 데이터로 만들기 위해서\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3879b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = 1/(1+torch.exp(-(x_train.matmul(W)+b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beccd6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<MulBackward0>)\n",
      "torch.Size([6, 1])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(hypothesis.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7eb2462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931]], grad_fn=<NegBackward>)\n",
      "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 손실함수 (cost function) 구현\n",
    "losses = -(y_train*torch.log(hypothesis)+\n",
    "          (1-y_train)*torch.log(1-hypothesis))\n",
    "print(losses)\n",
    "cost = losses.mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f792250",
   "metadata": {},
   "source": [
    "# binary에 대한 cost를 자동으로 만들어주는 함수\n",
    "- 앞에 한 것들을 한번에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68747f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd7431",
   "metadata": {},
   "source": [
    "# 전체 트레이닝 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60597fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모델 W, b / optimizer\n",
    "# 2. epoch 수 설정\n",
    "# 3. epoch 동안 => (\n",
    "#     (1) 가설함수, 손실함수 계산 / \n",
    "#     (2) cost를 통해서 gradient, 업데이트\n",
    "#     (3) 일정 단위마다 결과 출력 (여기에서는 비용 출력 - cost.item())\n",
    "#                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfae1569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.693147\n",
      "Epoch  100/1000 Cost: 0.134722\n",
      "Epoch  200/1000 Cost: 0.080643\n",
      "Epoch  300/1000 Cost: 0.057900\n",
      "Epoch  400/1000 Cost: 0.045300\n",
      "Epoch  500/1000 Cost: 0.037261\n",
      "Epoch  600/1000 Cost: 0.031673\n",
      "Epoch  700/1000 Cost: 0.027556\n",
      "Epoch  800/1000 Cost: 0.024394\n",
      "Epoch  900/1000 Cost: 0.021888\n",
      "Epoch 1000/1000 Cost: 0.019852\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros((2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정 : SGD를 가지고 W와 b를 러닝레이트가 1인 상태로 훈련\n",
    "optimizer = optim.SGD([W,b], lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # cost 계산\n",
    "    hypothesis = 1/(1+torch.exp(-(x_train.matmul(W)+b)))\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad() # 기존에 혹시 gradient 구해 놓은것이 있으면 0으로\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {:4d}/{} Cost: {:.6f}\".format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec32b6f",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6845d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = correct_prediction.sum().item() / len(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee67c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7648e-04],\n",
      "        [3.1608e-02],\n",
      "        [3.8977e-02],\n",
      "        [9.5622e-01],\n",
      "        [9.9823e-01]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W)+b) \n",
    "# 지금은 x_train 데이터가 들어있지만 x_test를 넣어야함\n",
    "print(hypothesis[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db9a0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True]])\n"
     ]
    }
   ],
   "source": [
    "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "print(prediction[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8b94f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]])\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = prediction.float() == y_train\n",
    "print(correct_prediction[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "246907e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has an accuracy of 100.00% for the training set.\n"
     ]
    }
   ],
   "source": [
    "# 예시를 위해서 train 데이터로 했기 때문에 100%\n",
    "accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cc0de0",
   "metadata": {},
   "source": [
    "# Higher implementation with class (실전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb0b371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005f2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30444dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(8,1)  # {W, b}, (?by8)을 예측하는 모델\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceb4ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6db939b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 0.472452 Accuracy 77.08%\n",
      "Epoch   10/100 Cost: 0.472388 Accuracy 77.21%\n",
      "Epoch   20/100 Cost: 0.472331 Accuracy 77.21%\n",
      "Epoch   30/100 Cost: 0.472278 Accuracy 77.21%\n",
      "Epoch   40/100 Cost: 0.472231 Accuracy 77.08%\n",
      "Epoch   50/100 Cost: 0.472188 Accuracy 77.08%\n",
      "Epoch   60/100 Cost: 0.472148 Accuracy 77.08%\n",
      "Epoch   70/100 Cost: 0.472112 Accuracy 77.08%\n",
      "Epoch   80/100 Cost: 0.472079 Accuracy 77.08%\n",
      "Epoch   90/100 Cost: 0.472048 Accuracy 77.08%\n",
      "Epoch  100/100 Cost: 0.472020 Accuracy 77.08%\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range (nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "    \n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 10번마다 로그 출력\n",
    "    if epoch % 10 ==0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "        print(\"Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%\".format(\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100\n",
    "        ))\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "652652cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.8913, -3.5399,  0.2260, -0.5833, -0.3301, -2.3799, -1.0032, -0.0717]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1705], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델의 파라미터 값 확인하기\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
